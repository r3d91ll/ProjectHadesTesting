# RAG Dataset Builder Configuration
# Comprehensive configuration file that supports all knowledge domains

# Directories
directories:
  cache: "../cache"  # Disk location for cache
  logs: "../logs"

# Disk storage locations (persistent storage)
source_documents: "../source_documents"  # Actual disk location for source documents
# Base directory for processed data
output_dir: "../rag_databases/pathrag_cpu_test1"

# Note: RAM disk configuration has been moved to scripts/ramdisk_config.sh
# This simplifies configuration and maintains proper separation of concerns
# The shell script handles RAM disk mounting, while the Python code just uses the provided paths

# Input/Output configuration
input:
  include:
    - "**/*.pdf"
    - "**/*.txt"
    - "**/*.md"
    - "**/*.py"
    - "**/*.js"
    - "**/*.java"
  exclude:
    - "**/README.md"
    - "**/LICENSE.md"  # We now handle license info in metadata
    - "**/.git/**"
    - "**/node_modules/**"

# Document processor configuration is in config.d/10-processors.yaml

# Text chunking configuration is in config.d/20-chunkers.yaml
chunker:
  type: "semantic"  # Default chunker type

# Embedding generation configuration is in config.d/30-embedders.yaml
embedder:
  type: "ollama"  # Use Ollama embedder for both CPU and GPU modes
  model_name: "nomic-embed-text"  # Use the specialized embedding model

# Output formatter configuration  
output:
  # Multiple output formatters can be enabled simultaneously
  formats:
    pathrag:
      enabled: true
      # Storage backend options
      backend: "networkx"  # Options: networkx, neo4j, igraph
      neo4j_connection: 
        uri: "bolt://localhost:7687"
        user: "neo4j"
        password: "password"
      # Output options
      include_metadata: true
      save_raw_text: true
      save_raw_embeddings: true
    
    vector_db:
      enabled: false
      type: "faiss"  # Options: faiss, chroma, milvus, qdrant, pinecone
      # Connection parameters for hosted services
      connection:
        api_key: ""  # For services like Pinecone
        environment: ""  # For services like Pinecone
      # Collection/index settings
      collection_name: "rag_dataset"
      dimension: 384  # Must match embedding dimension
      distance_metric: "cosine"
      # Output options
      include_metadata: true
    
    huggingface:
      enabled: false
      # Dataset settings
      dataset_name: "rag_dataset"
      push_to_hub: false
      hf_token: ""  # HF token for pushing to Hub
      # Format options
      include_embeddings: true
      include_metadata: true
      include_chunks: true

# Collection settings are now in config.d/18-collection.yaml

# Knowledge domain-specific search terms are now in config.d/19-domains.yaml

# Processing configuration is in config.d/15-processing.yaml

# Logging configuration is in config.d/12-logging.yaml

# Plugin discovery settings are in config.d/13-plugins.yaml

# Performance tracking configuration is in config.d/25-arize-phoenix.yaml

# Licensing settings are in config.d/14-licensing.yaml

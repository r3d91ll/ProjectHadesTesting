# GPU-based Embedder Configuration for PathRAG Dataset Builder
# This configuration is applied when using the --gpu flag

# Override the default embedder to use Ollama for GPU acceleration
embedder:
  type: "ollama"  # Use Ollama embedder for GPU processing
  use_gpu: true
  model_name: "nomic-embed-text"  # Explicitly set model name at top level too

embedders:
  # Configure Ollama embedder for GPU processing
  ollama:
    type: "ollama"
    model_name: "nomic-embed-text"  # Using specialized embedding model
    host: "localhost"
    port: 11434
    batch_size: 32  # Larger batch size for specialized embedding model
    cache_embeddings: true

# Processing configuration
processing:
  batch_size: 10  # Process documents in batches of 10
  num_workers: 4  # Fewer workers for GPU processing to avoid bottlenecks
  use_cpu_only: false  # Use GPU for processing

# Disable collection to prevent downloading documents again
# This is critical to ensure we don't download papers during GPU test
collection:
  enabled: false

# Embedder Configurations for RAG Dataset Builder
# This file configures various embedding models and services

embedders:
  # OpenAI embeddings configuration
  openai:
    type: "openai"
    model: "text-embedding-3-small"
    dimensions: 1536
    batch_size: 50
    cache_embeddings: true
    api_key: "${OPENAI_API_KEY}"  # Loaded from environment variable
    timeout: 60  # seconds
    retry_attempts: 3
    
  # Sentence Transformers configuration (CPU is the default)
  sentence_transformers:
    type: "sentence_transformers"
    model: "all-mpnet-base-v2"
    dimensions: 768
    batch_size: 128  # Larger batch size for CPU
    cache_embeddings: true
    device: "cpu"  # Default to CPU (use --gpu flag to enable GPU processing)
    normalize_embeddings: true
    num_threads: 24  # Use multiple CPU threads
    
  # Hugging Face Transformers configuration
  huggingface:
    type: "huggingface"
    model: "intfloat/e5-small-v2"
    dimensions: 384
    batch_size: 64  # Larger batch size for CPU
    cache_embeddings: true
    device: "cpu"  # Default to CPU (use --gpu flag to enable GPU processing)
    use_fp16: false  # Disable FP16 for CPU
    num_threads: 24  # Use multiple CPU threads
    use_auth_token: "${HF_API_KEY}"  # Loaded from environment variable, optional
    
  # BGE embeddings configuration
  bge:
    type: "bge"
    model: "BAAI/bge-large-en-v1.5"
    dimensions: 1024
    batch_size: 64  # Larger batch size for CPU
    cache_embeddings: true
    device: "cpu"  # Default to CPU (use --gpu flag to enable GPU processing)
    use_fp16: false  # Disable FP16 for CPU
    num_threads: 24  # Use multiple CPU threads
    
  # Ollama embeddings configuration
  ollama:
    type: "ollama"
    model_name: "nomic-embed-text"  # Specialized embedding model
    host: "localhost"
    port: 11434
    batch_size: 32  # Larger batch size for specialized embedding model
    cache_embeddings: true
    max_workers: 8  # Number of concurrent workers
    
  # BERT embeddings configuration
  bert:
    type: "bert"
    model: "bert-base-uncased"
    dimensions: 768
    batch_size: 64
    cache_embeddings: true
    device: "cpu"  # Default to CPU (use --gpu flag to enable GPU processing)
    use_fp16: false  # Disable FP16 for CPU
    num_threads: 24  # Use multiple CPU threads
    batch_size: 64  # Larger batch size for CPU
    cache_embeddings: true
    device: "cpu"  # Default to CPU (use --gpu flag to enable GPU processing)
    pooling_strategy: "mean"  # 'mean', 'cls', 'max'
    num_threads: 24  # Use multiple CPU threads
    
  # Custom embedding service (RESTful API) configuration
  custom_api:
    type: "api"
    url: "http://localhost:8000/embeddings"
    dimensions: 1024
    batch_size: 50
    cache_embeddings: true
    headers:
      authorization: "Bearer ${CUSTOM_API_KEY}"
    timeout: 60  # seconds
